import io, re
import pandas as pd
from datetime import datetime
import streamlit as st
import json, os

# =========================
# Helpers gerais
# =========================
PROC_10D = re.compile(r"(?<!\\d)(\\d{10})(?!\\d)")
DATE_8D = re.compile(r"\\b(\\d{8})\\b")

def try_read_text(file):
    try:
        return file.getvalue().decode("latin-1", errors="ignore")
    except Exception:
        file.seek(0)
        return file.getvalue().decode("utf-8", errors="ignore")

def detect_jul_2025(text):
    for token in DATE_8D.findall(text):
        for fmt in ("%d%m%Y", "%Y%m%d"):
            try:
                d = datetime.strptime(token, fmt)
                if d.year == 2025 and d.month == 7:
                    return True
            except Exception:
                continue
    return False

def extract_codes(text):
    return PROC_10D.findall(text)

def round2(x):
    try:
        return round(float(x), 2)
    except:
        return None

# =========================
# Auditoria ‚Äì validadores
# =========================
def validate_tiss_csv(df, fonte_nome="TISS"):
    findings = []
    required_cols = ["numero_guia","cid10","tuss_codigo","qtd","vl_unit","vl_total"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        findings.append(dict(regra_id="TISS_CAMPOS_OBR", gravidade="alta",
                             registro_id="-", descricao=f"Colunas ausentes: {missing}",
                             como_corrigir="Adicionar colunas exigidas ao CSV antes da an√°lise.",
                             impacto_estimado_RS=0))
        return pd.DataFrame(findings)

    for c in ["qtd","vl_unit","vl_total"]:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    for i, row in df.iterrows():
        rid = str(row.get("numero_guia", i))
        if pd.isna(row.get("cid10")) or str(row.get("cid10")).strip() == "":
            findings.append(dict(regra_id="TISS_CID_OBR", gravidade="alta", registro_id=rid,
                                 descricao="CID-10 ausente.",
                                 como_corrigir="Preencher CID-10 conforme laudo/diagn√≥stico.",
                                 impacto_estimado_RS=None))
        if pd.isna(row.get("tuss_codigo")) or str(row.get("tuss_codigo")).strip() == "":
            findings.append(dict(regra_id="TISS_TUSS_OBR", gravidade="alta", registro_id=rid,
                                 descricao="TUSS ausente.",
                                 como_corrigir="Preencher c√≥digo TUSS vigente.",
                                 impacto_estimado_RS=None))
        if not (pd.isna(df.at[i,"qtd"]) or pd.isna(df.at[i,"vl_unit"]) or pd.isna(df.at[i,"vl_total"])):
            calc = df.at[i,"qtd"] * df.at[i,"vl_unit"]
            if abs(calc - df.at[i,"vl_total"]) > 0.01:
                findings.append(dict(regra_id="TISS_FINANCEIRO", gravidade="media", registro_id=rid,
                                     descricao=f"vl_total ({df.at[i,'vl_total']}) != qtd*vl_unit ({round2(calc)}).",
                                     como_corrigir="Ajustar quantidade/valor unit√°rio ou total.",
                                     impacto_estimado_RS=abs(calc-df.at[i,"vl_total"])))
    return pd.DataFrame(findings)

def validate_fixed_lines(text, fonte_nome="FIXO"):
    lines = text.splitlines()
    if not lines:
        return pd.DataFrame([dict(regra_id="ARQ_VAZIO", gravidade="alta", registro_id="-",
                                  descricao="Arquivo sem linhas.",
                                  como_corrigir="Reexportar arquivo do sistema.",
                                  impacto_estimado_RS=0)])
    lens = [len(l.rstrip("\\r\\n")) for l in lines]
    mode_len = max(set(lens), key=lens.count)
    pct_diff = sum(1 for L in lens if L != mode_len) / len(lens) * 100

    findings = []
    if pct_diff > 5:
        findings.append(dict(regra_id="FIXO_COMPRIMENTO", gravidade="media", registro_id="-",
                             descricao=f"{pct_diff:.1f}% das linhas diferem do comprimento modal ({mode_len}).",
                             como_corrigir="Verificar layout/quebras de linha; reexportar.",
                             impacto_estimado_RS=0))

    has_codes = any(PROC_10D.search(l) for l in lines)
    has_jul25 = any(detect_jul_2025(l) for l in lines)
    if not has_codes:
        findings.append(dict(regra_id="SIGTAP_AUSENTE", gravidade="alta", registro_id="-",
                             descricao="N√£o foram encontrados c√≥digos de 10 d√≠gitos (SIGTAP).",
                             como_corrigir="Confirmar se o arquivo cont√©m os procedimentos.",
                             impacto_estimado_RS=0))
    if not has_jul25:
        findings.append(dict(regra_id="COMPETENCIA_DUVIDA", gravidade="baixa", registro_id="-",
                             descricao="N√£o detectei datas de julho/2025 nas linhas.",
                             como_corrigir="Verificar compet√™ncia do lote.",
                             impacto_estimado_RS=0))
    return pd.DataFrame(findings)

# =========================
# UI principal
# =========================
st.set_page_config(page_title="Auditoria & Pain√©is (SUS + Privado)", layout="wide")
st.title("üß† Auditoria & Pain√©is ‚Äî SUS (AIH/BPA/APAC) + Privado (TISS/TUSS)")
st.caption("Movement Innovation Solutions")

tab1, tab2, tab3, tab4 = st.tabs(["üîé Auditoria", "üè• Painel SUS", "üè∑Ô∏è Painel Privado", "üìö SIGTAP (Jul/2025)"])

# ---- TAB 1: Auditoria
with tab1:
    with st.sidebar:
        st.header("Par√¢metros da Auditoria")
        competencia = st.text_input("Compet√™ncia (AAAAMM)", value="202507")
        n_files = st.number_input("Quantos arquivos voc√™ vai enviar?", min_value=1, max_value=10, value=1, step=1)

    uploaded = []
    for i in range(int(n_files)):
        col1, col2 = st.columns([3,2])
        with col1:
            f = st.file_uploader(f"Arquivo {i+1}", type=None, key=f"fu_{i}")
        with col2:
            tipo = st.selectbox("Tipo", ["AIH_fixo","BPA_fixo","APAC_fixo","TISS_CSV"], key=f"tipo_{i}")
        uploaded.append((f,tipo))

    if st.button("Rodar Auditoria"):
        all_findings, det_rows = [], []
        for i, (f,tipo) in enumerate(uploaded, start=1):
            if not f: 
                continue
            fname = f.name
            st.write(f"**Processando:** `{fname}` ({tipo})")

            if tipo == "TISS_CSV":
                try:
                    df = pd.read_csv(f)
                except Exception:
                    f.seek(0)
                    df = pd.read_excel(f)
                st.info("Esperado: numero_guia, cid10, tuss_codigo, qtd, vl_unit, vl_total ...")
                findings = validate_tiss_csv(df, "TISS")
                if not findings.empty:
                    st.dataframe(findings)
                all_findings.append(("TISS", findings))
                st.write("Pr√©via TISS (200 linhas):")
                st.dataframe(df.head(200).copy())
            else:
                text = try_read_text(f)
                findings = validate_fixed_lines(text, tipo)
                if not findings.empty:
                    st.dataframe(findings)
                all_findings.append((tipo, findings))
                lines = text.splitlines()
                for idx, ln in enumerate(lines[:500], start=1):
                    codes = extract_codes(ln)
                    if codes:
                        det_rows.append(dict(arquivo=fname, line_idx=idx, codes_10d=";".join(codes), n_codes=len(codes)))

        xls_bytes = io.BytesIO()
        with pd.ExcelWriter(xls_bytes, engine="openpyxl") as writer:
            for fonte, df_f in all_findings:
                df_tmp = (df_f if df_f is not None and not df_f.empty
                          else pd.DataFrame(columns=["regra_id","gravidade","registro_id","descricao","como_corrigir","impacto_estimado_RS"]))
                df_tmp.to_excel(writer, sheet_name=f"{fonte}_erros", index=False)
            det_df = pd.DataFrame(det_rows) if det_rows else pd.DataFrame(columns=["arquivo","line_idx","codes_10d","n_codes"])
            det_df.to_excel(writer, sheet_name="Detalhe_codigos", index=False)
            resumo = []
            for fonte, df_f in all_findings:
                if df_f is None or df_f.empty: 
                    continue
                top = df_f["regra_id"].value_counts().head(5).to_dict()
                resumo.append(dict(fonte=fonte, top5_regra_ids=str(top)))
            pd.DataFrame(resumo).to_excel(writer, sheet_name="Resumo_executivo", index=False)

        st.success("Auditoria conclu√≠da!")
        st.download_button("‚¨áÔ∏è Baixar Correcoes_Imediatas.xlsx",
                           data=xls_bytes.getvalue(),
                           file_name="Correcoes_Imediatas.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        # ===== IA: Resumo Executivo + Plano de A√ß√£o =====
        st.markdown("---")
        st.subheader("üß† Analisar com IA")
        if st.button("Gerar Resumo Executivo (IA)"):
            meta = {"competencia": competencia}
            findings_pack = all_findings  # [(fonte, df)]
            resultado = ia_priorizar_e_sugerir(findings_pack, meta)

            # Mostrar resumo
            st.markdown(resultado["resumo_md"])

            # Mostrar a√ß√µes
            if resultado["acoes"] is not None and not resultado["acoes"].empty:
                st.write("**Plano de A√ß√£o Priorizado**")
                st.dataframe(resultado["acoes"])
            else:
                st.info("Sem a√ß√µes estruturadas retornadas para este conjunto.")

            # Downloads: Markdown e Excel (a√ß√µes)
            md_bytes = io.BytesIO(resultado["resumo_md"].encode("utf-8"))
            st.download_button(
                "‚¨áÔ∏è Baixar Resumo_IA.md",
                data=md_bytes.getvalue(),
                file_name="Resumo_IA.md",
                mime="text/markdown"
            )
            if resultado["acoes"] is not None and not resultado["acoes"].empty:
                out_xls = io.BytesIO()
                with pd.ExcelWriter(out_xls, engine="openpyxl") as w:
                    resultado["acoes"].to_excel(w, sheet_name="Plano_de_Acao", index=False)
                    # Guardar citacoes (se houver)
                    pd.DataFrame(resultado.get("citacoes", [])).to_excel(w, sheet_name="Citacoes", index=False)
                st.download_button(
                    "‚¨áÔ∏è Baixar Plano_de_Acao.xlsx",
                    data=out_xls.getvalue(),
                    file_name="Plano_de_Acao.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

            st.success("An√°lise de IA conclu√≠da.")

        except Exception as e:
            # Cai para fallback
            pass

    # ===== Fallback (sem IA): sumariza√ß√£o determin√≠stica =====
    vc = view["regra_id"].value_counts().head(5).to_dict() if "regra_id" in view.columns else {}
    perdas = view["impacto_estimado_RS"].fillna(0).sum() if "impacto_estimado_RS" in view.columns else 0
    resumo = f"""### Resumo Executivo (Autom√°tico)
- Compet√™ncia: **{meta.get('competencia','(n√£o informada)')}**
- Top regras: **{vc}**
- Estimativa de impacto (somat√≥rio dispon√≠vel): **R$ {perdas:,.2f}**
- Pr√≥ximas a√ß√µes:
  1. Corrigir campos obrigat√≥rios (CID/TUSS) nas guias pendentes.
  2. Conferir diverg√™ncias **vl_total ‚â† qtd √ó vl_unit** nas guias sinalizadas.
  3. Revisar compatibilidade cl√≠nica (CID ‚Üî procedimento) usando SIGTAP/TUSS vigente.
  4. Anexar laudos obrigat√≥rios e reprocessar.
  5. Reprocessar lote e monitorar **clean-claim** no pr√≥ximo ciclo.
"""
    acoes = []
    # Seleciona at√© 7 regras mais frequentes para o plano
    for i, (reg, count) in enumerate(vc.items(), start=1):
        acoes.append({
            "prioridade": "P1" if i <= 3 else "P2",
            "regra_id": reg,
            "gravidade": "alta" if i <= 3 else "media",
            "fonte": "",
            "registro_id": "",
            "descricao": f"Tratar {reg} (ocorr√™ncias: {count})",
            "como_corrigir": "Corrigir registros sinalizados e revalidar.",
            "impacto_estimado_RS": None,
            "responsavel_sugerido": "Faturamento",
            "prazo_dias": 5 if i <= 3 else 10
        })
    return {"resumo_md": resumo, "acoes": pd.DataFrame(acoes), "citacoes": []}

# ---- TAB 2: Painel SUS
with tab2:
    st.subheader("Painel de Risco de Glosa SUS ‚Äì Template")
    st.write("Gera um Excel com Indicadores, Matriz de Risco e Dashboard. Voc√™ pode editar metas e colar produ√ß√£o (BPA/APAC/AIH).")

    default_indic = pd.DataFrame({
        "Indicador": [
            "Pr√©-natal (6 cons. at√© 12¬™ sem.)",
            "Pr√©-natal (testes r√°pidos gestantes)",
            "Sa√∫de Bucal (gestantes)",
            "Citopatol√≥gico",
            "Hipertens√£o acompanhada",
            "Diabetes acompanhada",
            "Vacina√ß√£o (P√≥lio/Penta)"
        ],
        "Valor(%)": [57, 44, 23, 20, 19, 6, 92],
        "Meta(%)":  [70, 60, 40, 40, 50, 40, 90]
    })
    st.dataframe(default_indic, use_container_width=True)

    if st.button("Gerar Excel SUS"):
        out = io.BytesIO()
        with pd.ExcelWriter(out, engine="openpyxl") as w:
            default_indic.to_excel(w, sheet_name="Indicadores SUS", index=False)
            # Matriz de risco
            df2 = default_indic.copy()
            def risco(row):
                if row["Valor(%)"] >= row["Meta(%)"]: return "Verde (Seguro)"
                if row["Valor(%)"] >= 0.7*row["Meta(%)"]: return "Amarelo (Aten√ß√£o)"
                return "Vermelho (Cr√≠tico)"
            df2["Risco"] = df2.apply(risco, axis=1)
            df2.to_excel(w, sheet_name="Matriz de Risco", index=False)
            # Importar Produ√ß√£o (vazia)
            pd.DataFrame({"Cole_aqui":"BPA/APAC/AIH"}).to_excel(w, sheet_name="Importar Producao", index=False)
            # Dashboard (texto)
            dash = pd.DataFrame({"Resumo":[
                "‚úÖ Vacina√ß√£o em n√≠vel seguro (92%).",
                "‚ö†Ô∏è Pr√©-natal, Sa√∫de Bucal, Citopatol√≥gico, Hipertens√£o e Diabetes com risco de perda.",
                "üî¥ Ponto mais cr√≠tico: Diabetes acompanhada (6% vs meta 40%)."
            ]})
            dash.to_excel(w, sheet_name="Dashboard", index=False)
        st.download_button("‚¨áÔ∏è Baixar painel_risco_glosa_SUS.xlsx",
                           data=out.getvalue(),
                           file_name="painel_risco_glosa_SUS.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# ---- TAB 3: Painel Privado
with tab3:
    st.subheader("Painel Privado ‚Äì TISS/TUSS (Template)")
    st.write("Gera um Excel com abas: Importar TISS, Valida√ß√µes, Matriz_Risco, Crosswalk_TUSS_CID, Param_Contratos e Dashboard.")

    if st.button("Gerar Excel Privado"):
        out = io.BytesIO()
        with pd.ExcelWriter(out, engine="openpyxl") as w:
            cols = ["lote_id","operadora","tipo_guia","numero_guia","data_atendimento",
                    "beneficiario","matricula","prestador_cnes","executante_cpf_cbo",
                    "cid10","tuss_codigo","tuss_descricao","qtd","vl_unit","vl_total",
                    "anexos_laudos","status_envio","motivo_glosa_ret"]
            pd.DataFrame(columns=cols).to_excel(w, sheet_name="Importar TISS", index=False)

            valid = pd.DataFrame([
                ["<preencher>","CAMPOS","CID-10 obrigat√≥rio para Interna√ß√£o","A verificar","Alta","Inserir CID-10 compat√≠vel"],
                ["<preencher>","TUSS","TUSS v√°lido na tabela vigente","A verificar","Alta","Verificar c√≥digo TUSS"],
                ["<preencher>","COMPAT","CID compat√≠vel com TUSS","A verificar","Alta","Revisar nexo cl√≠nico"],
                ["<preencher>","ANEXOS","Laudo exigido para procedimento","A verificar","M√©dia","Anexar laudo"],
                ["<preencher>","FINANCEIRO","vl_total = qtd*vl_unit","A verificar","Baixa","Corrigir quantidade/valor"]
            ], columns=["numero_guia","regra","descricao_regra","resultado","gravidade","acao_sugerida"])
            valid.to_excel(w, sheet_name="Validacoes", index=False)

            risco = pd.DataFrame([
                ["Operadora A", 88, 14, 52, "", "CID x TUSS"],
                ["Operadora B", 93, 9, 35, "", "Anexo faltante"],
                ["Operadora C", 96, 6, 28, "", "Erro financeiro"],
            ], columns=["operadora","clean_claim_rate(%)","glosa_inicial(%)","DSO(dias)","risco","principal_causa"])
            risco.to_excel(w, sheet_name="Matriz_Risco", index=False)

            cx = pd.DataFrame([["40.05.01.012","Exemplo ‚Äì Procedimento","G56.0; G56.1; G57.0","Exemplo; substituir pela tabela oficial/contratual."]],
                              columns=["tuss_codigo","tuss_descricao","cid10_sugeridos","observacoes"])
            cx.to_excel(w, sheet_name="Crosswalk_TUSS_CID", index=False)

            contratos = pd.DataFrame([
                ["Operadora A","SP/SADT","N",1500,"",30,"‚Äî"],
                ["Operadora B","Internacao","S-DRG","","",45,"Pacote inclui honor√°rio."]
            ], columns=["operadora","linha","pacote_DRG","teto_evento(R$)","coparticipacao(%)","prazo_pagto(dias)","observacao"])
            contratos.to_excel(w, sheet_name="Param_Contratos", index=False)

            dash = pd.DataFrame({"Como_usar":[
                "1) Cole o CSV do XML na aba 'Importar TISS'.",
                "2) Use 'Validacoes' para marcar regras atendidas/pendentes.",
                "3) Preencha 'Param_Contratos' por operadora.",
                "4) Consolide m√©tricas na 'Matriz_Risco'."
            ]})
            dash.to_excel(w, sheet_name="Dashboard", index=False)

        st.download_button("‚¨áÔ∏è Baixar painel_privado_TISS_TUSS_template.xlsx",
                           data=out.getvalue(),
                           file_name="painel_privado_TISS_TUSS_template.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# ---- TAB 4: SIGTAP
with tab4:
    st.subheader("Consolida√ß√£o SIGTAP ‚Äì Jul/2025")
    st.write("Envie arquivos AIH/BPA/APAC (texto/linha fixa). O app extrai c√≥digos de 10 d√≠gitos, sinaliza Jul/2025 e gera planilha para cruzar com SIGTAP.")

    aih = st.file_uploader("AIH (linha fixa)", type=None, key="sig_aih")
    bpa = st.file_uploader("BPA (linha fixa)", type=None, key="sig_bpa")
    apac = st.file_uploader("APAC (linha fixa)", type=None, key="sig_apac")

    if st.button("Gerar Excel SIGTAP (Jul/2025)"):
        def process(file, fonte):
            if not file: return []
            text = try_read_text(file)
            rows = []
            for idx, ln in enumerate(text.splitlines(), start=1):
                codes = extract_codes(ln)
                jul = detect_jul_2025(ln)
                if codes:
                    rows.append([fonte, idx, ";".join(codes), len(codes), int(jul)])
            return rows

        rows = []
        rows += process(aih, "AIH")
        rows += process(bpa, "BPA_oftalmo")
        rows += process(apac, "APAC_cirurgia")

        df_det = pd.DataFrame(rows, columns=["fonte","line_idx","codes_10d","n_codes","has_julho_2025"])
        # agrega√ß√£o simples por c√≥digo/fonte
        agg = []
        if not df_det.empty:
            for fonte, g in df_det.groupby("fonte"):
                for code, g2 in g.assign(code=g["codes_10d"].str.split(";")).explode("code").groupby("code"):
                    agg.append([code, fonte, g2.shape[0], g2["has_julho_2025"].sum()])
        df_agg = pd.DataFrame(agg, columns=["codigo","fonte","qtd","qtd_julho"])

        out = io.BytesIO()
        with pd.ExcelWriter(out, engine="openpyxl") as w:
            # Resumo
            resumo = pd.DataFrame({
                "Arquivos_lidos":[
                    f"AIH: {'OK' if aih else 'n√£o enviado'}",
                    f"BPA: {'OK' if bpa else 'n√£o enviado'}",
                    f"APAC: {'OK' if apac else 'n√£o enviado'}",
                    "Cole SIGTAP vigente em 'SIGTAP_importe' (AAAAMM=202507)."
                ]
            })
            resumo.to_excel(w, sheet_name="Resumo", index=False)

            # SIGTAP_importe (vazia para colar tabela oficial)
            pd.DataFrame(columns=["CO_PROCEDIMENTO","NO_PROCEDIMENTO","VL_SH","VL_SA","VL_OPM","VL_TOTAL_SUGERIDO","COMPETENCIA"]).to_excel(
                w, sheet_name="SIGTAP_importe", index=False
            )

            # Consolidado_proc (com f√≥rmulas para buscar descri√ß√£o/valores ao colar a SIGTAP)
            if df_agg.empty:
                df_base = pd.DataFrame(columns=["codigo","desc_sigtap","vl_sh","vl_sa","vl_opm","vl_unit_total","qtd_total","qtd_julho","valor_total_estimado"])
            else:
                df_base = (df_agg.pivot_table(index="codigo", columns="fonte", values="qtd", aggfunc="sum", fill_value=0)
                                .assign(qtd_total=lambda d: d.sum(axis=1))
                                .assign(qtd_julho=0)
                                .reset_index()[["codigo","qtd_total","qtd_julho"]])
            # cria planilha e depois injeta f√≥rmulas por coluna (Excel far√° o VLOOKUP)
            df_base.assign(desc_sigtap="", vl_sh=0, vl_sa=0, vl_opm=0, vl_unit_total=0, valor_total_estimado=0)\
                   .to_excel(w, sheet_name="Consolidado_proc", index=False)
        # OBS: deixamos o usu√°rio colar a SIGTAP e ent√£o fazer os PROCs/VLOOKUP no Excel.

        st.success("Planilha gerada!")
        st.download_button("‚¨áÔ∏è Baixar consolidacao_SIGTAP_julho2025.xlsx",
                           data=out.getvalue(),
                           file_name="consolidacao_SIGTAP_julho2025.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
def ia_priorizar_e_sugerir(findings_df_list, meta):
import json, os
rows = []
for fonte, df in findings_df_list:
if df is None or df.empty:
continue
tmp = df.copy()
tmp["fonte"] = fonte
rows.append(tmp)

if not rows:
return {
"resumo_md": "### Resumo Executivo (IA)\n\nNenhum achado relevante encontrado.",
"acoes": pd.DataFrame(columns=[
"prioridade","regra_id","gravidade","fonte","registro_id",
"descricao","como_corrigir","impacto_estimado_RS","responsavel_sugerido","prazo_dias"
]),
"citacoes": []
}

allf = pd.concat(rows, ignore_index=True)
view = allf.head(300).copy()

# Captura chave da OpenAI
api_key = os.getenv("OPENAI_API_KEY", None)
try:
if "OPENAI_API_KEY" in st.secrets:
api_key = st.secrets["OPENAI_API_KEY"]
except Exception:
pass

prompt_sistema = (
"Voc√™ √© um analista s√™nior de faturamento hospitalar (SUS + Privado). "
"Priorize riscos de glosa, estime impacto financeiro, explique causa raiz "
"e proponha a√ß√µes corretivas objetivas."
)

prompt_usuario = {
"meta": meta,
"campos_df": list(view.columns),
"amostra_achados": view.fillna("").to_dict(orient="records"),
"formato_esperado": {
"resumo_md": "Markdown com Top-5 causas, perda evit√°vel, 7‚Äì10 a√ß√µes priorizadas e ganhos r√°pidos.",
"acoes": [{
"prioridade":"P1|P2|P3","regra_id":"...","gravidade":"alta|media|baixa","fonte":"TISS|AIH|BPA|APAC",
"registro_id":"...","descricao":"...","como_corrigir":"...","impacto_estimado_RS":"num",
"responsavel_sugerido":"...","prazo_dias":"int"
}],
"citacoes": [{"tipo":"regra|contrato|tabela","referencia":"..."}]
}
}

# ===== Tenta IA =====
if api_key:
try:
from openai import OpenAI
client = OpenAI(api_key=api_key)
resp = client.chat.completions.create(
model="gpt-4o-mini",
messages=[
{"role":"system","content": prompt_sistema},
{"role":"user","content": json.dumps(prompt_usuario, ensure_ascii=False)}
],
temperature=0.2
)
txt = resp.choices[0].message.content or ""
# Tenta extrair JSON; se n√£o houver, usa o texto como resumo
payload = {}
try:
start = txt.find("{")
end = txt.rfind("}")
if start != -1 and end != -1:
payload = json.loads(txt[start:end+1])
except Exception:
payload = {}
acoes_df = pd.DataFrame(payload.get("acoes", [])) if payload.get("acoes") else pd.DataFrame(columns=[
"prioridade","regra_id","gravidade","fonte","registro_id",
"descricao","como_corrigir","impacto_estimado_RS","responsavel_sugerido","prazo_dias"
])
return {
"resumo_md": payload.get("resumo_md", txt if txt else "### Resumo Executivo (IA)\n\nSem texto."),
"acoes": acoes_df,
"citacoes": payload.get("citacoes", [])
}
except Exception:
# cai no fallback autom√°tico
pass

# ===== Fallback determin√≠stico (sem IA ou erro na chamada) =====
vc = view["regra_id"].value_counts().head(5).to_dict() if "regra_id" in view.columns else {}
perdas = view["impacto_estimado_RS"].fillna(0).sum() if "impacto_estimado_RS" in view.columns else 0.0
resumo = f"""### Resumo Executivo (Autom√°tico)
- Compet√™ncia: **{meta.get('competencia','(n√£o informada)')}**
- Top regras: **{vc}**
- Estimativa de impacto (somat√≥rio dispon√≠vel): **R$ {perdas:,.2f}**
- Pr√≥ximas a√ß√µes:
1. Corrigir campos obrigat√≥rios (CID/TUSS) nas guias pendentes.
2. Ajustar diverg√™ncias financeiras (vl_total ‚â† qtd √ó vl_unit).
3. Revisar compatibilidade cl√≠nica (CID ‚Üî procedimento) via SIGTAP/TUSS.
4. Anexar laudos obrigat√≥rios e reprocessar.
5. Monitorar clean-claim e DSO no pr√≥ximo ciclo.
"""
acoes = []
for i, (reg, count) in enumerate(vc.items(), start=1):
acoes.append({
"prioridade": "P1" if i <= 3 else "P2",
"regra_id": reg,
"gravidade": "alta" if i <= 3 else "media",
"fonte": "",
"registro_id": "",
"descricao": f"Tratar {reg} (ocorr√™ncias: {count})",
"como_corrigir": "Corrigir registros sinalizados e revalidar.",
"impacto_estimado_RS": None,
"responsavel_sugerido": "Faturamento",
"prazo_dias": 5 if i <= 3 else 10
})
return {"resumo_md": resumo, "acoes": pd.DataFrame(acoes), "citacoes": []}
